title: "Pygmalion"  
description: "Pygmalion is a proof-of-concept dialogue model from PygmalionAI"
api: "POST https://run.cerebrium.ai/pygmalion-2-7b-webhook/predict"

---

Pygmalion is a proof-of-concept dialogue model based on EleutherAI's GPT-Neo or GPT-J. We currently have the following Pygmalion models available below, however, if you would like any other model, please contact support and we can quickly add it for you. To deploy it, you will need to use one of the identifiers below:

- Pygmalion 2.7b: `pygmalion-2-7b`
- Pygmalion 6b: `pygmalion-6b`

Where Pymalion 6B is a proof-of-concept dialogue model based on EleutherAI's GPT-J-6B and Pymalion 2.7B is the smaller model based on EleutherAI's GPT-Neo-2.7B.

Once you've deployed a Pygmalion model, you can supply the endpoint with a prompt. The model can be used as a regular text generation model, but it'll perform best if the input prompt adheres to the following format:

```
[CHARACTER]'s Persona: [A few sentences about the character you want the model to play]
<START>
[DIALOGUE HISTORY]
You: [Your input message here]
[CHARACTER]:
```

Where `[CHARACTER]` is, as you can probably guess, the name of the character you want the model to portray, `\<START\> `should be used verbatim as a delimiter token to separate persona and scenario data from the dialogue, and `[DIALOGUE HISTORY]` is chat history so the model can have some conversational context to draw from.

Apart from chat history, you can also just add example conversations in `[DIALOGUE HISTORY]` to show how the character should speak â€” ideally at the beginning, so it doesn't get confused as to what's conversation history vs. character definition.

#### Request Parameters

<RequestExample>
```bash Request
  curl --location --request POST 'https://run.cerebrium.ai/pygmalion-2-7b-webhook/predict' \
      --header 'Authorization: <API_KEY>' \
      --header 'Content-Type: application/json' \
      --data-raw '{
        {
            "prompt": "Michael\'s Persona: A big strong man with a big heart\n<START>\nYou: How are you doing on this wonderful day?\n Michael:",
            "max_length": 100,
            "temperature": 0.5,
            "stopping_criteria": [
                "The end."
            ],
            "top_p": 0.5,
            "typical_p": 0.9,
            "repetition_penalty": 0.5,
            "top_k": 10
        }
    }'
```
</RequestExample>

<ParamField header="Authorization" type="string" required>
  This is the Cerebrium API key used to authenticate your request. You can get it from your Cerebrium dashboard.
</ParamField>
<ParamField body="prompt" type="string" required>
   The prompt you would like Pygmalion to process. Make sure to follow the expected format for the best response
</ParamField>
<ParamField body="max_length" type="string" optional>
   The max number of tokens you would like Pygmalion to generate
</ParamField>
<ParamField body="temperature" type="string" optional>
   Value between 0 and 1 which controls randomness. Lowering the number results in less random completions.
</ParamField>
<ParamField body="stopping_criteria" type="list" optional>
   A list of words/phrases that can be used to change when to stop generation.
</ParamField>
<ParamField body="top_p" type="float" optional>
  If set to < 1, only the smallest set of most probable tokens with probabilities that add up to top_p or higher are kept for generation.
</ParamField>
<ParamField body="typical_p" type="float" optional>
  Value of typical_p between 0 and 1 inclusive, defaults to 0.9.
</ParamField>
<ParamField body="repetition_penalty" type="float" optional>
  The parameter for repetition penalty. 1.0 means no penalty
</ParamField>
<ParamField body="top_k" type="float" optional>
  The number of highest probability vocabulary tokens to keep for top-k-filtering.
</ParamField>
<ParamField body="pad_token_id" type="integer" optional>
  The id of the padding token.
</ParamField>

<ResponseExample>

```json Response
{
  "run_id": "<UNIQUE_RUN_ID>",
  "run_time_ms": 39995.2712059021,
  "message": "Successfully generated text",
  "result": "Michaels's Persona: A big strong man with a big heart\n<START>\nYou: How are you doing on this wonderful day?\n Michael: Oh, this is a wonderful day! It's the perfect kind of day to be in love... I'm going to walk around, wearing a sweater and jeans today. I want to show you my strength and my love for you. Oh, I'm just wonderful."
}
```

</ResponseExample>

#### Response Parameters

<ResponseField name="run_id" type="string" required>
  The unique id associated to the API request.
</ResponseField>
<ResponseField name="run_time_ms" type="string" required>
  The amount of time it took to run your model. This is what you will be charged
  for.
</ResponseField>
<ResponseField name="message" type="string" required>
  A message from our server notifying you if you run was successful or not
</ResponseField>
<ResponseField name="result" type="string" required>
  The result generated from Pygmalion
</ResponseField>
