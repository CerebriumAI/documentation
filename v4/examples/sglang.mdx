---
title: "Deploy a Vision Language Model with SGLang"
description: "Build an intelligent ad analysis system that evaluates advertisements across multiple dimensions"
---

In this comprehensive tutorial, we'll explore how to deploy a powerful vision language model using SGLang on Cerebrium. We'll build an intelligent ad analysis system that evaluates advertisements across multiple dimensions: message clarity, visual appearance, and call-to-action effectiveness.

SGLang (Structured Generation Language) represents a paradigm shift in how we work with Large Language Models. Unlike traditional inference engines that treat LLMs as "black box APIs," SGLang provides a structured programming framework specifically designed for complex, multi-step LLM workflows.

SGLang is being used in production by teams at xAI and Deepseek to power their core language model capabilities making it a trusted choice.

### Key Advantages Over Traditional Inference Engines

| Feature | Traditional Engines (vLLM, TGI) | SGLang |
|---------|--------------------------------|---------|
| **Programming Model** | Sequential API calls with manual prompt chaining | Native structured logic with `gen()`, `fork()`, `join()`, `select()` |
| **Memory Management** | Basic KV caching, often discarded between calls | **RadixAttention**: Intelligent prefix-aware cache reuse (up to 6x faster) |
| **Output Control** | Hope and pray for correct formatting | **Compressed FSMs**: Guaranteed structured output (JSON, XML, etc.) |
| **Parallel Processing** | Manual batching and coordination | Built-in `fork()` and `join()` for parallel execution |
| **Performance** | Standard inference optimization | PyTorch-native with `torch.compile()`, quantization, sparse inference |



### Production-Proven Performance

SGLang isn't just theoreticalâ€”it's powering real applications at scale:
- **xAI's Grok**: Uses SGLang for core conversational logic
- **DeepSeek V3**: Official SGLang support across multiple hardware platforms
- **PyTorch Ecosystem**: Now an official part of PyTorch with LMSYS backing

## What We're Building: Intelligent Ad Analysis System

Our application will:
1. Accept an advertisement image and business context
2. Analyze three key dimensions in parallel:
   - **Message Clarity**: How clear and understandable is the message?
   - **Visual Appearance**: How appealing and professional is the design?
   - **Call-to-Action**: How effective is the CTA at driving action?
3. Provide structured feedback with scores and recommendations

## Prerequisites

Before we begin, ensure you have:
- Cerebrium CLI installed and configured
- Basic Python knowledge
- Understanding of vision-language models

## Step 1: Project Setup

First, let's create our project structure:

```bash
cerebrium init sglang-ad-analyzer
cd sglang-ad-analyzer
```

## Step 2: Configure Dependencies

Update your `cerebrium.toml` file with the required dependencies:

```toml
[cerebrium.dependencies.pip]
sglang = "latest"
torch = "2.4.0"
torchvision = "latest"
transformers = "latest"
accelerate = "latest"
pillow = "latest"
pydantic = "latest"
requests = "latest"
```

## Step 3: Hardware Configuration

For the Qwen3-VL-30B-A3B-Instruct-FP8 model, we need substantial GPU memory. Configure your hardware in `cerebrium.toml`:

```toml
[cerebrium.hardware]
region = "us-east-1"
provider = "aws"
compute = "AMPERE_A100"  # 80GB VRAM for 30B parameter model
cpu = 8
memory = 64.0
gpu_count = 1

[cerebrium.scaling]
min_replicas = 0
max_replicas = 3
cooldown = 300  # Longer cooldown for large models
```

## Step 4: Implement the Ad Analysis Application

Create your `main.py` file:

```python
import sglang as sgl
from sglang import function, gen, select, fork, join
from pydantic import BaseModel
from typing import List, Dict, Any
import torch
from PIL import Image
import base64
import io
import json

# Request/Response Models
class AdAnalysisRequest(BaseModel):
    image_base64: str
    business_context: str
    target_audience: str = "general consumers"
    campaign_goals: str = "increase brand awareness and drive sales"

class AnalysisResult(BaseModel):
    aspect: str
    score: int
    explanation: str
    recommendations: List[str]

class AdAnalysisResponse(BaseModel):
    overall_score: float
    analyses: List[AnalysisResult]
    summary: str
    actionable_insights: List[str]

# Initialize SGLang runtime with Qwen3-VL model
@sgl.function
def analyze_ad_aspect(s, image, aspect, business_context, target_audience, campaign_goals):
    """Analyze a specific aspect of an advertisement"""
    
    s += sgl.user(f"""
You are an expert marketing analyst. Analyze this advertisement image focusing specifically on {aspect}.

Business Context: {business_context}
Target Audience: {target_audience}  
Campaign Goals: {campaign_goals}

Please provide:
1. A score from 1-10 for {aspect}
2. Detailed explanation of your assessment
3. Specific recommendations for improvement

Focus only on {aspect} in your analysis.
""")
    
    s += sgl.assistant_begin()
    s += "Score: "
    s += gen("score", regex=r"[1-9]|10")
    s += "\n\nExplanation: "
    s += gen("explanation", max_tokens=200, stop="\n\nRecommendations:")
    s += "\n\nRecommendations:\n"
    s += gen("recommendations", max_tokens=150)
    s += sgl.assistant_end()

@sgl.function  
def comprehensive_ad_analysis(s, image, business_context, target_audience, campaign_goals):
    """Perform comprehensive ad analysis across multiple dimensions"""
    
    # Define analysis aspects
    aspects = [
        "message clarity and communication effectiveness",
        "visual design and aesthetic appeal", 
        "call-to-action strength and conversion potential"
    ]
    
    # Fork execution for parallel analysis
    forks = s.fork(len(aspects))
    
    # Analyze each aspect in parallel
    for i, (fork, aspect) in enumerate(zip(forks, aspects)):
        fork += analyze_ad_aspect.run(
            image=image,
            aspect=aspect,
            business_context=business_context,
            target_audience=target_audience,
            campaign_goals=campaign_goals
        )
    
    # Join results
    s += s.join(forks)
    
    # Generate overall summary
    s += sgl.user("""
Based on the three analyses above, provide:
1. An overall score (average of the three scores)
2. A brief summary of the ad's strengths and weaknesses
3. Top 3 actionable insights for improvement

Format as JSON:
{
    "overall_score": <score>,
    "summary": "<summary>",
    "actionable_insights": ["<insight1>", "<insight2>", "<insight3>"]
}
""")
    
    s += sgl.assistant(gen("final_analysis", max_tokens=300))

# Model initialization (runs once at startup)
def load_model():
    """Initialize the SGLang runtime with Qwen3-VL model"""
    
    # Set up SGLang runtime
    runtime = sgl.Runtime(
        model_path="Qwen/Qwen3-VL-30B-A3B-Instruct-FP8",
        tokenizer_path="Qwen/Qwen3-VL-30B-A3B-Instruct-FP8",
        tp_size=1,  # Tensor parallelism size
        trust_remote_code=True,
    )
    
    sgl.set_default_backend(runtime)
    return runtime

# Global model instance
runtime = load_model()

def process_image(image_base64: str) -> Image.Image:
    """Convert base64 string to PIL Image"""
    image_data = base64.b64decode(image_base64)
    image = Image.open(io.BytesIO(image_data))
    return image

def parse_analysis_result(result_text: str, aspect: str) -> AnalysisResult:
    """Parse SGLang output into structured result"""
    lines = result_text.strip().split('\n')
    
    # Extract score
    score_line = next((line for line in lines if line.startswith('Score:')), '')
    score = int(score_line.split(':')[1].strip()) if score_line else 5
    
    # Extract explanation
    explanation_start = next((i for i, line in enumerate(lines) if 'Explanation:' in line), -1)
    rec_start = next((i for i, line in enumerate(lines) if 'Recommendations:' in line), len(lines))
    
    explanation = ' '.join(lines[explanation_start+1:rec_start]).strip() if explanation_start != -1 else ""
    
    # Extract recommendations
    recommendations = []
    if rec_start < len(lines):
        rec_text = ' '.join(lines[rec_start+1:]).strip()
        recommendations = [rec.strip('- ').strip() for rec in rec_text.split('\n') if rec.strip()]
    
    return AnalysisResult(
        aspect=aspect,
        score=score,
        explanation=explanation,
        recommendations=recommendations[:3]  # Limit to top 3
    )

def analyze_ad(request: AdAnalysisRequest) -> AdAnalysisResponse:
    """Main analysis function"""
    
    # Process image
    image = process_image(request.image_base64)
    
    # Run comprehensive analysis
    state = comprehensive_ad_analysis.run(
        image=image,
        business_context=request.business_context,
        target_audience=request.target_audience,
        campaign_goals=request.campaign_goals
    )
    
    # Parse results
    aspects = ["message clarity", "visual appearance", "call-to-action"]
    analyses = []
    
    # Extract individual analysis results
    for i, aspect in enumerate(aspects):
        if i < len(state.messages):
            result_text = state.messages[i].get('content', '')
            analysis = parse_analysis_result(result_text, aspect)
            analyses.append(analysis)
    
    # Parse final analysis
    final_analysis_text = state.messages[-1].get('content', '{}')
    try:
        final_data = json.loads(final_analysis_text)
        overall_score = final_data.get('overall_score', 0)
        summary = final_data.get('summary', '')
        actionable_insights = final_data.get('actionable_insights', [])
    except:
        overall_score = sum(a.score for a in analyses) / len(analyses) if analyses else 0
        summary = "Analysis completed successfully."
        actionable_insights = ["Review the detailed analysis for specific recommendations."]
    
    return AdAnalysisResponse(
        overall_score=overall_score,
        analyses=analyses,
        summary=summary,
        actionable_insights=actionable_insights
    )

# Cerebrium endpoint
def predict(request: AdAnalysisRequest) -> Dict[str, Any]:
    """Main prediction endpoint for Cerebrium"""
    try:
        result = analyze_ad(request)
        return result.dict()
    except Exception as e:
        return {
            "error": str(e),
            "message": "Failed to analyze advertisement"
        }
```

## Step 5: Complete Deployment Configuration

Update your complete `cerebrium.toml`:

```toml
[cerebrium.build]
predict_data = '''
{
    "image_base64": "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg==",
    "business_context": "Tech startup selling productivity software",
    "target_audience": "busy professionals",
    "campaign_goals": "increase trial signups"
}
'''
hide_public_endpoint = false
disable_animation = false
disable_build_logs = false
disable_syntax_check = false
disable_predict = false
log_level = "INFO"

[cerebrium.deployment]
name = "sglang-ad-analyzer"
python_version = "3.11"
include = ["./*", "main.py", "cerebrium.toml"]
exclude = ["./tests", "./__pycache__"]
docker_base_image_url = "nvidia/cuda:12.1.1-runtime-ubuntu22.04"

[cerebrium.hardware]
region = "us-east-1"
provider = "aws"
compute = "AMPERE_A100"
cpu = 8
memory = 64.0
gpu_count = 1

[cerebrium.scaling]
min_replicas = 0
max_replicas = 3
cooldown = 300

[cerebrium.dependencies.pip]
sglang = "latest"
torch = "2.4.0"
torchvision = "latest"
transformers = "latest"
accelerate = "latest"
pillow = "latest"
pydantic = "latest"
requests = "latest"

[cerebrium.dependencies.conda]

[cerebrium.dependencies.apt]
```

## Step 6: Deploy Your Application

Deploy your SGLang-powered ad analyzer:

```bash
cerebrium deploy sglang-ad-analyzer
```

## Step 7: Test Your Deployment

Once deployed, test your application with a sample request:

```bash
curl -X POST "https://api.aws.us-east-1.cerebrium.ai/v4/p-<YOUR-PROJECT-ID>/sglang-ad-analyzer/predict" \
  -H "Authorization: Bearer <YOUR-TOKEN>" \
  -H "Content-Type: application/json" \
  -d '{
    "image_base64": "<BASE64_ENCODED_AD_IMAGE>",
    "business_context": "E-commerce fashion brand targeting millennials",
    "target_audience": "fashion-conscious millennials aged 25-35",
    "campaign_goals": "increase online sales and brand awareness"
  }'
```

### Example Response

```json
{
  "overall_score": 7.3,
  "analyses": [
    {
      "aspect": "message clarity",
      "score": 8,
      "explanation": "The headline is clear and compelling, directly addressing the target audience's pain point...",
      "recommendations": [
        "Consider adding a subheadline for additional context",
        "Use more action-oriented language",
        "Highlight the unique value proposition more prominently"
      ]
    },
    {
      "aspect": "visual appearance", 
      "score": 7,
      "explanation": "The design is modern and appealing with good use of color and typography...",
      "recommendations": [
        "Improve contrast for better readability",
        "Consider using higher quality product images",
        "Add more white space for cleaner look"
      ]
    },
    {
      "aspect": "call-to-action",
      "score": 7,
      "explanation": "The CTA button is visible but could be more prominent...",
      "recommendations": [
        "Use more contrasting colors for the CTA button",
        "Make the CTA text more specific and urgent",
        "Consider adding a secondary CTA option"
      ]
    }
  ],
  "summary": "This ad shows strong message clarity but has room for improvement in visual design and CTA optimization. The overall concept is solid with clear targeting.",
  "actionable_insights": [
    "Enhance CTA visibility with contrasting colors and urgent language",
    "Improve visual hierarchy to guide viewer attention better", 
    "Add social proof elements to increase credibility"
  ]
}
```

## Advanced Features and Optimizations

### 1. Batch Processing

For analyzing multiple ads simultaneously:

```python
@sgl.function
def batch_analyze_ads(s, images, business_contexts):
    """Analyze multiple ads in parallel"""
    forks = s.fork(len(images))
    
    for fork, image, context in zip(forks, images, business_contexts):
        fork += comprehensive_ad_analysis.run(
            image=image,
            business_context=context,
            target_audience="general",
            campaign_goals="increase engagement"
        )
    
    return s.join(forks)
```

### 2. Custom Scoring Criteria

Extend the analysis with custom business metrics:

```python
@sgl.function
def analyze_with_custom_criteria(s, image, criteria_list):
    """Analyze ad against custom business criteria"""
    forks = s.fork(len(criteria_list))
    
    for fork, criterion in zip(forks, criteria_list):
        fork += f"Evaluate this ad specifically for: {criterion}\n"
        fork += "Score (1-10): "
        fork += gen("score", regex=r"[1-9]|10")
        fork += "\nReasoning: "
        fork += gen("reasoning", max_tokens=100)
    
    return s.join(forks)
```

### 3. Performance Monitoring

Add logging and monitoring:

```python
import time
import logging

def predict(request: AdAnalysisRequest) -> Dict[str, Any]:
    start_time = time.time()
    
    try:
        result = analyze_ad(request)
        
        # Log performance metrics
        processing_time = time.time() - start_time
        logging.info(f"Ad analysis completed in {processing_time:.2f}s")
        
        return {
            **result.dict(),
            "processing_time": processing_time
        }
    except Exception as e:
        logging.error(f"Analysis failed: {str(e)}")
        return {"error": str(e)}
```

## Key Benefits of This SGLang Implementation

1. **Parallel Processing**: All three analysis dimensions run simultaneously, reducing total processing time by ~3x
2. **Structured Output**: Guaranteed JSON formatting eliminates parsing errors
3. **Memory Efficiency**: RadixAttention reuses computations across similar prompts
4. **Scalability**: Built-in load balancing and intelligent scheduling
5. **Maintainability**: Clean, readable code structure with reusable components

## Troubleshooting Common Issues

### Memory Issues
If you encounter CUDA out of memory errors:
- Reduce `max_tokens` in generation calls
- Use model quantization (FP8 is already optimized)
- Consider using multiple smaller GPUs with tensor parallelism

### Slow Cold Starts
- Increase `min_replicas` to 1 for faster response times
- Use smaller models for development/testing
- Implement model caching strategies

### Output Formatting Issues
- Verify your regex patterns in `gen()` calls
- Use more specific stop tokens
- Implement fallback parsing logic

## Conclusion

This tutorial demonstrated how to build a sophisticated ad analysis system using SGLang's unique capabilities. By leveraging parallel execution, structured generation, and intelligent memory management, we created a production-ready application that outperforms traditional inference approaches.

SGLang's programming model makes complex LLM workflows more maintainable, efficient, and reliableâ€”perfect for demanding production environments where performance and accuracy matter.

## Next Steps

- Experiment with different vision-language models
- Add more analysis dimensions (brand consistency, emotional appeal, etc.)
- Implement A/B testing capabilities for ad variations
- Integrate with marketing automation platforms
- Add real-time feedback and learning capabilities

For more advanced SGLang patterns and optimizations, check out the [official SGLang documentation](https://github.com/sgl-project/sglang) and explore the [PyTorch ecosystem integration](https://pytorch.org/blog/sglang-pytorch/).
