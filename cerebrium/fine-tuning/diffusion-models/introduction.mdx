---
title: "Introduction"
description: "Quickly and conveniently fine-tune your diffusion model with just one command!"
---


<Note>
  Cerebrium's fine-tuning functionality is in public beta and so we are adding
  more functionality each week! Currently, we only support the training of
  stable-diffusion models. If you have an urgent requirement, we can help you just reach
  out to [support](mailto\:support@cerebrium.ai) 
</Note>


Diffusion models are incredible at generating images from art, designs, logos and beyond. Fine-tuning stable diffusion models allows you to create your very own personal model which generates images of your object or in your style.  
Using Cerebrium's trainer, you can fine-tune your model with one command using your very own data without having to worry about any of the hardware or implementation details!

Our diffusion fine-tuner leverages parameter efficient finetuning (PEFT) and low-rank adaptors (LORA) to only train a small subset of the diffusion model. This drastically improves training time while focusing on the parts of the model that make the biggest difference to your results, saving you time while yielding results comparable to full network finetuning.

While in the beta phase, the following models are supported for fine-tuning on Cerebrium:

| Model Name                           | Huggingface Path               |
| ------------------------------------ | ------------------------------ |
| Stable Diffusion V1.5                | runwayml/stable-diffusion-v1-5 |
| Stable Diffusion V2.1 (coming soon!) | stabilityai/stable-diffusion-2 |

We're actively working on adding more models based on demand so please let the team know if there's a model you would like us to add support for.
