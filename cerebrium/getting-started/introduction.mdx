---
title: Introduction
description: Getting started on the Cerebrium platform
---

Cerebrium is a serverless infrastructure platform for building and scaling data and AI workloads.

- Launch your code in the cloud in seconds
- Define your own [containers environments](/cerebrium/container-images/defining-container-images) or bring your own [Dockerfile](/cerebrium/container-images/custom-dockerfiles)
- Run [CPUs](/cerebrium/hardware/cpu-and-memory) or [GPUs](/cerebrium/hardware/using-gpus) at scale—with support for thousands of concurrent containers
- [Scale](/cerebrium/scaling/scaling-apps) based on concurrency, Requests per second or CPU/Memory utilization,
- Serve [WebSockets](/cerebrium/endpoints/websockets), [REST APIs](/cerebrium/endpoints/inference-api), or any [ASGI-compatible app](/cerebrium/container-images/custom-web-servers)
- Store model weights, files, and more with [distributed storage](/cerebrium/storage/managing-files)
- Pay only for the compute you use — [billed by the second](https://www.cerebrium.ai/pricing)

Cerebrium abstracts the infrastructure complexity so you can focus on building AI products users love!

## Getting Started

Setting up and deploying an app on Cerebrium takes just a few steps:

### 1. Install the CLI

<Tabs>
<Tab title="Python (pip)">

```bash
pip install cerebrium
```

</Tab>
<Tab title="macOS (Homebrew)">

```bash
brew tap cerebriumai/tap
brew install cerebrium
```

</Tab>
<Tab title="Linux">

```bash
# Ubuntu/Debian
wget https://github.com/CerebriumAI/cerebrium/releases/latest/download/cerebrium_linux_amd64.deb
sudo dpkg -i cerebrium_linux_amd64.deb

# Or binary installation
curl -L https://github.com/CerebriumAI/cerebrium/releases/latest/download/cerebrium_cli_linux_amd64.tar.gz | tar xz
sudo mv cerebrium /usr/local/bin/
```

</Tab>
<Tab title="Windows">

```powershell
# PowerShell (Run as Administrator)
Invoke-WebRequest -Uri "https://github.com/CerebriumAI/cerebrium/releases/latest/download/cerebrium_cli_windows_amd64.zip" -OutFile "cerebrium.zip"
Expand-Archive -Path "cerebrium.zip" -DestinationPath "."
# Add cerebrium.exe to PATH
```

</Tab>
</Tabs>

### 2. Login to CLI

```bash
cerebrium login  # Redirects to your browser for authentication
```

### 3. Initialize a Project

```bash
cerebrium init my-first-app
cd my-first-app
```

This creates a basic project with `main.py` for app code and `cerebrium.toml` for configuration. This is what the main.py file contains:

```python
def run(prompt: str):
    print(f"Running on Cerebrium: {prompt}")

    return {"my_result": prompt}
```

### 4. Run code remotely

We can then run this function in the cloud and pass it a prompt.

```bash
cerebrium run main.py::run --prompt "Hello World!"
```

Your should see logs that output the prompt you sent in - this is running in the cloud!

Use the `run` functionality for quick code iteration and testing snippets or once-off scripts that require large CPU/GPU in the cloud.

Let us now turn this into a scalable REST endpoint - something we could put in production!

### 5. Deploy your app

Run the following command:

```bash
cerebrium deploy
```

This will turn the function into a callable persistent [endpoint](/cerebrium/endpoints/inference-api). that accepts json parameters (prompt) and can scale to 1000s of requests automatically!

Once deployed, an app becomes callable through a POST endpoint `https://api.aws.us-east-1.cerebrium.ai/v4/{project-id}/{app-name}/{function-name}` and takes a json parameter, prompt

Great! You made it!

Join our Community [Discord](https://discord.gg/ATj6USmeE2) for support and updates.

## How It Works

Cerebrium uses containerization to ensure consistent environments and reliable scaling for apps. When code is deployed, Cerebrium packages it with all necessary dependencies into a container image. This image serves as a blueprint for creating instances that handle incoming requests. The system automatically manages scaling, creating new instances when traffic increases and removing them during quiet periods.

For a detailed explanation of how Cerebrium builds and manages container images, see our [Defining Container Images Guide](/cerebrium/container-images/defining-container-images).

<Info>
  Content-Aware Storage forms the foundation of Cerebrium's speed. This system
  intelligently manages container images by understanding their content
  structure. When launching new instances, it pulls only the specific files.
  This targeted approach significantly reduces cold start times and optimizes
  resource usage.
</Info>

## Further Examples

Below are a few tutorials to explore in order to learn more about the functionality Cerebrium has to offer:

- [Serve a OpenAI Compatible LLM with vLLM](/v4/examples/gpt-oss)
- [Deploy a Twilio Voice Agent with Pipecat](/v4/examples/twilio-voice-agent)
- [Run a Hyper-Parameter Sweep Training Llama 3.2](/v4/examples/wandb-sweep)
- [Run a Gradio Chat Inferface](/v4/examples/asgi-gradio-interface)
