---
title: Understanding Metrics Graphs
---

Cerebrium provides real-time metrics graphs to help you monitor your application's resource usage and performance. These graphs offer valuable insights into how your application is utilizing resources and can help you identify potential bottlenecks or optimization opportunities.

## Available Metrics

The dashboard displays the following metrics for your applications:

### Requests

The Requests graph shows the number of concurrent requests being processed by your application over time.

**What it shows:** This graph displays the number of requests waiting in the queue or currently being processed by your application. Higher values indicate increased load on your system.

**Data source:** For individual containers (pods), this metric comes from `revision_queue_depth`, which measures the depth of the request queue for a specific pod. For the entire application, it uses `activator_request_concurrency`, which tracks the total concurrent requests across all instances.

**Nuances and gotchas:**
- Spikes in this graph often correlate with increased latency in your application
- If this value consistently remains high, consider increasing your replica count or adjusting your scaling configuration
- Zero values don't necessarily mean your application isn't receiving traffic - it could mean requests are being processed immediately without queuing

### GPU

The GPU graph shows the GPU memory usage of your application over time.

**What it shows:** This graph displays the amount of GPU memory (VRAM) being used by your application in gigabytes. It represents the maximum memory used across all GPUs allocated to your application.

**Data source:** This metric comes from `DCGM_FI_DEV_FB_USED`, which is provided by NVIDIA's Data Center GPU Manager (DCGM). The value is divided by 1024 to convert from megabytes to gigabytes.

**Nuances and gotchas:**
- GPU memory usage includes both model weights and intermediate activations
- Memory spikes often occur during inference or when loading models
- If you're seeing values close to your GPU's total memory, you may be at risk of out-of-memory errors
- Some frameworks may not release GPU memory immediately after use, resulting in a "sawtooth" pattern
- Zero values may indicate your application isn't utilizing the GPU, which could mean your model isn't properly loaded on the GPU

### CPU

The CPU graph shows the CPU utilization of your application over time.

**What it shows:** This graph displays the maximum rate of CPU usage in cores. For example, a value of 2.0 means your application is using the equivalent of 2 full CPU cores.

**Data source:** This metric comes from `container_cpu_usage_seconds_total`, which measures the cumulative CPU time consumed by the container. The `rate()` function is applied to calculate the per-second usage over the specified time window.

**Nuances and gotchas:**
- CPU usage can spike during model loading, preprocessing, or when handling requests that don't utilize the GPU
- Values consistently near your configured CPU limit may indicate CPU bottlenecks
- The graph shows the maximum rate across all instances, not the average
- CPU throttling may occur if your application exceeds its allocated CPU resources

### Memory

The Memory graph shows the RAM usage of your application over time.

**What it shows:** This graph displays the maximum memory usage in gigabytes across all instances of your application.

**Data source:** This metric comes from `container_memory_usage_bytes`, which measures the total memory used by the container. The value is divided by 1024Â³ to convert from bytes to gigabytes.

**Nuances and gotchas:**
- Memory includes both your application code, loaded models (when not on GPU), and any data being processed
- Memory usage typically increases during model loading and may decrease once models are transferred to GPU
- If memory usage approaches your configured limit, your application may be terminated with an OOM (Out of Memory) error
- Memory usage patterns can help identify memory leaks or inefficient resource usage

### Workers

The Workers graph shows the number of active replicas (instances) of your application over time.

**What it shows:** This graph displays the number of ready replicas that are currently serving traffic for your application.

**Data source:** This metric comes from `kube_deployment_status_replicas_ready`, which tracks the number of replicas that are ready to serve traffic in a Kubernetes deployment.

**Nuances and gotchas:**
- Changes in this graph reflect your application's auto-scaling behavior
- Increases indicate scaling up to handle more traffic, while decreases show scaling down during periods of lower demand
- If this value remains at 0, your application may be experiencing deployment issues
- The time it takes for this number to increase reflects your application's cold start time

## Reading Time-Series Graphs

When interpreting the metrics graphs, keep these points in mind:

- **Time ranges:** For ranges greater than 1 day, the x-axis displays dates. For ranges of 1 day or less, only times are shown.
- **Resolution:** You can adjust the resolution (Low, Medium, High) to change the granularity of the data points.
- **Zooming:** You can zoom in on a specific time period by clicking and dragging across the graph.
- **Filtering:** You can filter metrics by specific container instances to troubleshoot issues with individual replicas.

## Using Metrics for Optimization

These metrics can help you optimize your application in several ways:

- **Scaling configuration:** Analyze the Requests and Workers graphs to fine-tune your scaling parameters
- **Resource allocation:** Use the CPU, Memory, and GPU graphs to right-size your resource requests
- **Performance bottlenecks:** Identify which resources are limiting your application's performance
- **Cost optimization:** Detect over-provisioned resources that could be reduced to lower costs

For more information on configuring CPU and memory resources, see the [CPU and Memory](/cerebrium/hardware/cpu-and-memory) documentation. For GPU configuration, refer to [Using GPUs](/cerebrium/hardware/using-gpus).
