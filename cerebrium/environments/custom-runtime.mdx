---
title: Using Custom Runtimes (Beta)
description: Configure custom ASGI or WSGI runtimes
---

The default Cortex runtime can be great for getting up and running and simple use cases. However, you may already have an application built, or need
more complex functionality built into your app such as custom authentication, dynamic batching, public endpoints or websockets.
The Cerebrium platform allows you to deploy a custom python-based runtime to achieve this. To illustrate how this works, let's
take a straightforward example ASGI webserver written in FastAPI called `main.py`:

```python
from fastapi import FastAPI

server = FastAPI()

@server.get("/hello")
async def hello():
    return {"message": "Hello Cerebrium!"}

@server.get("/health")
asycn def health():
    return "Ok"
```

To enable us to deploy this application, we modify our `cerebrium.toml` with a 'cerebrium.runtime.custom' section.
There are 3 parameters in this section:

| parameter              | description                                                                         | type       | default                                                                |
| ---------------------- | ----------------------------------------------------------------------------------- | ---------- | ---------------------------------------------------------------------- |
| `entrypoint`           | The command used to enter your application as a list of strings, run from `/cortex` | list\[str] | \["uvicorn", "app.main:server", "--host", "0.0.0.0", "--port", "8000"] |
| `port`                 | The port your application runs on                                                   | int        | 8000                                                                   |
| `healthcheck_endpoint` | The endpoint the application uses to relay that it is ready to receive requests.    | string     | "/readyz"                                                              |

An example of a config section for a custom runtime for our main file may look something like this:

```toml
[cerebrium.deployment]
name = "my-app"
python_version = "3.10"
...

[cerebrium.runtime.custom]
entrypoint = ["uvicorn", "app.main:server", "--host", "0.0.0.0", "--port", "8080"]
port = 8080
healthcheck_endpoint = "/health"

...
```

An important note about entrypoints. Since your source code is in `/cortex/app`, your entrypoint must be run from the `app` directory
(e.g. if you want to run `main.py`, the entrypoint would be: `python app/main.py`). Furthermore, notice that any port used in the entrypoint
matches the specified port.

Depending on whether you deploy an ASGI application or an app with a self-container webserver, you may need to install an ASGI runtime
to run your app just as you would usually. In this case, we are using an ASGI server (FastAPI), so we will need to install `uvicorn`.
Specify this in your dependencies:

```toml
...

[cerebrium.dependencies.pip]
fastapi = "latest"
uvicorn = "latest"

...
```

Conversely, it is possible to run WSGI or apps with self contained servers. For example, you could deploy
a VLLM app using only the 'cerebrium.runtime.custom' and 'cerebrium.dependencies.pip' sections and **no**
Python code!

```toml
...

[cerebrium.runtime.custom]
entrypoint = [
  'vllm',
  'serve',
  'meta-llama/Meta-Llama-3-8B-Instruct',
  '--host',
  '0.0.0.0',
  '--port',
  '8000',
  '--device',
  'cuda',
  '--dtype',
  'auto',
  '--trust-remote-code',
  '--enable-chunked-prefill',
  '--disable-fastapi-docs',
  '--max_num_batched_tokens',
  '1024'
]
port = 8000
healthcheck_endpoint = "/health"

[cerebrium.dependencies.pip]
torch = "latest"
vllm = "latest"

...
```

Once you have made the necessary changes to your configuration, you are ready to deploy! You can deploy as normal
and our system will detect you are running a custom runtime automatically.

```bash
cerebrium deploy -y
```

Your call signature is exactly the same as when you deploy a Cortex application. Every endpoint your custom server exposes will be available on
`api.cortex.cerebrium/{project-id}/{app-name}/an/example/endpoint`
