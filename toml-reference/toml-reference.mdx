---
title: TOML Reference
description: Complete reference for all parameters available in Cerebrium's default `cerebrium.toml` configuration file.
---

The configuration is organized into the following main sections:

- **[cerebrium.deployment]** Core settings like app name and file inclusion rules
- **[cerebrium.runtime.cortex]** Default Cerebrium-managed Python runtime (build settings)
- **[cerebrium.runtime.python]** Custom Python ASGI/WSGI web server settings
- **[cerebrium.runtime.docker]** Custom Dockerfile settings
- **[cerebrium.hardware]** Compute resources including CPU, memory, and GPU specifications
- **[cerebrium.scaling]** Auto-scaling behavior and replica management
- **[cerebrium.dependencies]** Package management for Python (pip), system (apt), and Conda dependencies

## Deployment Configuration

The `[cerebrium.deployment]` section defines core deployment settings that apply to all runtime types.

| Option                            | Type     | Default                | Description                                                                                                  |
| --------------------------------- | -------- | ---------------------- | ------------------------------------------------------------------------------------------------------------ |
| name                              | string   | required               | Desired app name                                                                                             |
| disable_auth                      | boolean  | false                  | Disable default token-based authentication on app endpoints                                                  |
| include                           | string[] | ["*"]                  | Files/patterns to include in deployment                                                                      |
| exclude                           | string[] | [".*"]                 | Files/patterns to exclude from deployment                                                                    |
| deployment_initialization_timeout | integer  | 600 (10 minutes)       | The max time to wait for app initialisation during build before timing out. Value must be between 60 and 830 |

## Runtime Configuration

Cerebrium supports three runtime types. You should only specify one runtime section in your configuration.

### Cortex Runtime (Default)

The `[cerebrium.runtime.cortex]` section configures the default Cerebrium-managed Python runtime. This is ideal for standard Python applications using the default Cortex framework.

| Option               | Type     | Default                | Description                                       |
| -------------------- | -------- | ---------------------- | ------------------------------------------------- |
| python_version       | string   | "3.11"                 | Python version to use (3.10, 3.11, 3.12)          |
| docker_base_image_url| string   | "debian:bookworm-slim" | Base Docker image                                 |
| shell_commands       | string[] | []                     | Commands to run at the end of the build           |
| pre_build_commands   | string[] | []                     | Commands to run before dependencies install       |
| use_uv               | boolean  | false                  | Use UV for faster Python package installation     |

**Example:**

```toml
[cerebrium.deployment]
name = "my-cortex-app"

[cerebrium.runtime.cortex]
python_version = "3.12"
docker_base_image_url = "debian:bookworm-slim"
use_uv = true
```

<Info>
  Changes to python_version or docker_base_image_url trigger full rebuilds since
  they affect the base environment.
</Info>

### Python Runtime (Custom ASGI/WSGI)

The `[cerebrium.runtime.python]` section configures custom Python web servers (ASGI/WSGI). Use this when you need full control over your web server implementation for features like custom authentication, dynamic batching, or WebSocket connections.

| Option               | Type     | Default                                                            | Description                                                                |
| -------------------- | -------- | ------------------------------------------------------------------ | -------------------------------------------------------------------------- |
| python_version       | string   | "3.11"                                                             | Python version to use (3.10, 3.11, 3.12)                                   |
| docker_base_image_url| string   | "debian:bookworm-slim"                                             | Base Docker image                                                          |
| shell_commands       | string[] | []                                                                 | Commands to run at the end of the build                                    |
| pre_build_commands   | string[] | []                                                                 | Commands to run before dependencies install                                |
| use_uv               | boolean  | false                                                              | Use UV for faster Python package installation                              |
| entrypoint           | string[] | ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"] | Command to start the application                                           |
| port                 | integer  | 8000                                                               | Port the application listens on                                            |
| healthcheck_endpoint | string   | ""                                                                 | HTTP path for health checks (empty uses TCP). Failure causes restart       |
| readycheck_endpoint  | string   | ""                                                                 | HTTP path for readiness checks (empty uses TCP). Failure stops routing     |

**Example:**

```toml
[cerebrium.deployment]
name = "my-fastapi-app"

[cerebrium.runtime.python]
python_version = "3.11"
entrypoint = ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
port = 8000
healthcheck_endpoint = "/health"
readycheck_endpoint = "/ready"

[cerebrium.dependencies.pip]
fastapi = "latest"
uvicorn = "latest"
```

<Info>
  The port specified in entrypoint must match the port parameter. All endpoints
  will be available at `https://api.aws.us-east-1.cerebrium.ai/v4/{project-id}/{app-name}/your/endpoint`
</Info>

### Docker Runtime (Custom Dockerfile)

The `[cerebrium.runtime.docker]` section configures deployments using custom Dockerfiles. Use this for non-Python applications or when you need complete control over the container build process.

| Option               | Type     | Default  | Description                                                                                                                                                                             |
| -------------------- | -------- | -------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| dockerfile_path      | string   | required | Relative path to a custom Dockerfile                                                                                                                                                    |
| entrypoint           | string[] | []       | Command to start the application. Required if Dockerfile has no CMD/ENTRYPOINT. **Always takes precedence over Dockerfile CMD/ENTRYPOINT when specified.**                             |
| port                 | integer  | 8000     | Port the application listens on                                                                                                                                                         |
| healthcheck_endpoint | string   | ""       | HTTP path for health checks (empty uses TCP). Failure causes the instance to restart                                                                                                    |
| readycheck_endpoint  | string   | ""       | HTTP path for readiness checks (empty uses TCP). Failure ensures the load balancer does not route to the instance                                                                       |

**Example:**

```toml
[cerebrium.deployment]
name = "my-docker-app"

[cerebrium.runtime.docker]
dockerfile_path = "./Dockerfile"
port = 8080
healthcheck_endpoint = "/health"
readycheck_endpoint = "/ready"
```

<Info>
  **Entrypoint Precedence:** When both `entrypoint` in `cerebrium.toml` and
  `CMD`/`ENTRYPOINT` in your Dockerfile are defined, the TOML `entrypoint`
  always takes precedence. This allows you to override your Dockerfile's default
  command at deploy time without modifying the Dockerfile itself.
</Info>

<Warning>
  When using `dockerfile_path`, all dependencies and build commands should be
  handled within the Dockerfile. The `[cerebrium.dependencies.*]` sections,
  `shell_commands`, and `pre_build_commands` will be ignored.
</Warning>

### UV Package Manager

UV is a fast Python package installer written in Rust that can significantly speed up deployment times. When enabled in `[cerebrium.runtime.cortex]` or `[cerebrium.runtime.python]`, UV will be used instead of pip for installing Python dependencies.

<Info>
UV typically installs packages 10-100x faster than pip, especially beneficial for:

- Large dependency trees
- Multiple packages
- Clean builds without cache

</Info>

**Example with UV enabled:**

```toml
[cerebrium.runtime.cortex]
use_uv = true
```

### Monitoring UV Usage

Check your build logs for these indicators:

- **UV_PIP_INSTALL_STARTED** - UV is successfully being used
- **PIP_INSTALL_STARTED** - Standard pip installation (when `use_uv` is `false`)

<Warning>
  While UV is compatible with most packages, some edge cases may cause build
  failures, such as legacy packages with non-standard metadata.
</Warning>

### Deploying with UV Lock Files

<Info>read only if you're using `pyproject.toml` and `uv.lock`</Info>

Generate your lock file locally. This creates a uv.lock file with exact dependency versions.

```bash
# In your project directory with pyproject.toml
uv sync
```

Export your locked dependencies to requirements.txt

```bash
uv pip compile pyproject.toml -o requirements.txt
# Or if you want to use the lock file:
uv pip compile uv.lock -o requirements.txt
```

Include in your deployment:

- Ensure requirements.txt is in your project directory
- Deploy with UV enabled

## Hardware Configuration

The `[cerebrium.hardware]` section defines compute resources.

| Option    | Type    | Default     | Description                          |
| --------- | ------- | ----------- | ------------------------------------ |
| cpu       | float   | required    | Number of CPU cores                  |
| memory    | float   | required    | Memory allocation in GB              |
| compute   | string  | "CPU"       | Compute type (CPU, AMPERE_A10, etc.) |
| gpu_count | integer | 0           | Number of GPUs                       |
| provider  | string  | "aws"       | Cloud provider                       |
| region    | string  | "us-east-1" | Deployment region                    |

<Warning>
  Memory refers to RAM, not GPU VRAM. Ensure sufficient memory for your
  workload.
</Warning>

## Scaling Configuration

The `[cerebrium.scaling]` section controls auto-scaling behavior.

| Option                    | Type    | Default                   | CLI Requirement | Description                                                                                                                                                                                             |
| ------------------------- | ------- | ------------------------- | --------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| min_replicas              | integer | 0                         | 2.1.2+          | Minimum running instances                                                                                                                                                                               |
| max_replicas              | integer | 2                         | 2.1.2+          | Maximum running instances                                                                                                                                                                               |
| replica_concurrency       | integer | 10                        | 2.1.2+          | Concurrent requests per replica                                                                                                                                                                         |
| response_grace_period     | integer | 3600                      | 2.1.2+          | Grace period in seconds                                                                                                                                                                                 |
| cooldown                  | integer | 1800                      | 2.1.2+          | Time window (seconds) that must pass at reduced concurrency before scaling down. Helps avoid cold starts from brief traffic dips.                                                                       |
| scaling_metric            | string  | "concurrency_utilization" | 2.1.2+          | Metric for scaling decisions (concurrency_utilization, requests_per_second, cpu_utilization, memory_utilization)                                                                                        |
| scaling_target            | integer | 100                       | 2.1.2+          | Target value for scaling metric (percentage for utilization metrics, absolute value for requests_per_second)                                                                                            |
| scaling_buffer            | integer | optional                  | 2.1.2+          | Additional replica capacity above what scaling metric suggests                                                                                                                                          |
| evaluation_interval       | integer | 30                        | 2.1.5+          | Time window in seconds over which metrics are evaluated before scaling decisions (6-300s)                                                                                                               |
| load_balancing            | string  | ""                        | 2.1.5+          | Algorithm for distributing traffic across replicas. Default: round-robin if replica_concurrency > 3, first-available otherwise. Options: round-robin, first-available, min-connections, random-choice-2 |
| roll_out_duration_seconds | integer | 0                         | 2.1.2+          | Gradually send traffic to new revision after successful build. Max 600s. Keep at 0 during development.                                                                                                  |

<Warning>
  Setting min_replicas > 0 maintains warm instances for immediate response but
  increases costs.
</Warning>

The `scaling_metric` options are:

- **concurrency_utilization**: Maintains a percentage of your replica_concurrency across instances. For example, with `replica_concurrency=200` and `scaling_target=80`, maintains 160 requests per instance.
- **requests_per_second**: Maintains a specific request rate across all instances. For example, `scaling_target=5` maintains 5 requests/s average across instances.
- **cpu_utilization**: Maintains CPU usage as a percentage of cerebrium.hardware.cpu. For example, with `cpu=2` and `scaling_target=80`, maintains 80% CPU utilization (1.6 CPUs) per instance.
- **memory_utilization**: Maintains RAM usage as a percentage of cerebrium.hardware.memory. For example, with `memory=10` and `scaling_target=80`, maintains 80% memory utilization (8GB) per instance.

<Info>
The scaling_buffer option is only available with concurrency_utilization and requests_per_second metrics.
It ensures extra capacity is maintained above what the scaling metric suggests.

For example, with `min_replicas=0` and `scaling_buffer=3`, the system will maintain 3 replicas as baseline capacity.

</Info>

## Dependencies

### Pip Dependencies

The `[cerebrium.dependencies.pip]` section lists Python package requirements.

```toml
[cerebrium.dependencies.pip]
torch = "==2.0.0"      # Exact version
numpy = "latest"       # Latest version
pandas = ">=1.5.0"     # Minimum version
```

### APT Dependencies

The `[cerebrium.dependencies.apt]` section specifies system packages.

```toml
[cerebrium.dependencies.apt]
ffmpeg = "latest"
libopenblas-base = "latest"
```

### Conda Dependencies

The `[cerebrium.dependencies.conda]` section manages Conda packages.

```toml
[cerebrium.dependencies.conda]
cuda = ">=11.7"
cudatoolkit = "11.7"
```

### Dependency Files

The `[cerebrium.dependencies.paths]` section allows using requirement files.

```toml
[cerebrium.dependencies.paths]
pip = "requirements.txt"
apt = "pkglist.txt"
conda = "conda_pkglist.txt"
```

## Complete Examples

### Cortex Runtime (Default)

```toml
[cerebrium.deployment]
name = "llm-inference"
disable_auth = false
include = ["*"]
exclude = [".*"]

[cerebrium.runtime.cortex]
python_version = "3.12"
docker_base_image_url = "debian:bookworm-slim"
use_uv = true
shell_commands = []
pre_build_commands = []

[cerebrium.hardware]
cpu = 4
memory = 16.0
compute = "AMPERE_A10"
gpu_count = 1
provider = "aws"
region = "us-east-1"

[cerebrium.scaling]
min_replicas = 0
max_replicas = 2
replica_concurrency = 10
response_grace_period = 3600
cooldown = 1800
scaling_metric = "concurrency_utilization"
scaling_target = 100
evaluation_interval = 30
roll_out_duration_seconds = 0

[cerebrium.dependencies.pip]
torch = "latest"
transformers = "latest"
```

### Python Runtime (FastAPI)

```toml
[cerebrium.deployment]
name = "fastapi-server"
disable_auth = false
include = ["*"]
exclude = [".*"]

[cerebrium.runtime.python]
python_version = "3.11"
entrypoint = ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
port = 8000
healthcheck_endpoint = "/health"
readycheck_endpoint = "/ready"

[cerebrium.hardware]
cpu = 4
memory = 16.0
compute = "AMPERE_A10"
gpu_count = 1
provider = "aws"
region = "us-east-1"

[cerebrium.scaling]
min_replicas = 0
max_replicas = 2
replica_concurrency = 10

[cerebrium.dependencies.pip]
torch = "latest"
transformers = "latest"
uvicorn = "latest"
fastapi = "latest"
```

### Docker Runtime

```toml
[cerebrium.deployment]
name = "rust-server"
include = ["*"]
exclude = [".*"]

[cerebrium.runtime.docker]
dockerfile_path = "./Dockerfile"
port = 8192
healthcheck_endpoint = "/health"
readycheck_endpoint = "/ready"

[cerebrium.hardware]
cpu = 4
memory = 16.0
compute = "CPU"
provider = "aws"
region = "us-east-1"

[cerebrium.scaling]
min_replicas = 0
max_replicas = 2
replica_concurrency = 10
```

## Backwards Compatibility

<Warning>
The following configuration patterns are deprecated but still supported for backwards compatibility.
We recommend migrating to the new runtime sections.
</Warning>

### Deprecated: Runtime fields in [cerebrium.deployment]

The following fields in `[cerebrium.deployment]` are deprecated. Please move them to the appropriate runtime section:

| Deprecated Field       | New Location                                                |
| ---------------------- | ----------------------------------------------------------- |
| python_version         | `[cerebrium.runtime.cortex]` or `[cerebrium.runtime.python]` |
| docker_base_image_url  | `[cerebrium.runtime.cortex]` or `[cerebrium.runtime.python]` |
| shell_commands         | `[cerebrium.runtime.cortex]` or `[cerebrium.runtime.python]` |
| pre_build_commands     | `[cerebrium.runtime.cortex]` or `[cerebrium.runtime.python]` |
| use_uv                 | `[cerebrium.runtime.cortex]` or `[cerebrium.runtime.python]` |

### Deprecated: [cerebrium.runtime.custom]

The `[cerebrium.runtime.custom]` section is deprecated. Please migrate to:

- `[cerebrium.runtime.python]` - For custom Python ASGI/WSGI applications
- `[cerebrium.runtime.docker]` - For custom Dockerfile deployments (when using `dockerfile_path`)
