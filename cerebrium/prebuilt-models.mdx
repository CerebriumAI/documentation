---
title: "Prebuilt Models"
description: "Deploy prebuilt models to an API."
---

Cerebrium provides prebuilt models that you can deploy to an API. You can use these models to get started with Cerebrium easily.

## Deployment
Deploying a prebuilt model is largely similar to deploying a custom model. The only difference is that you do not need to upload a model file.
Instead, you specify which prebuilt model you want to deploy using the corresponding identifer.

```python
from cerebrium import deploy, model_type
# Deploy a prebuilt Stable Diffusion Model
endpoint = deploy((model_type.PREBUILT, "stable-diffusion-text"), 'my-pipeline', "<API_KEY>")
```
<Note>
    You can not use prebuilt models in ensembles or with post-processing functions. They should be contained within single model pipelines only.
</Note>

You can check out the available models below!

## Prebuilt Models
### Image Models
#### Stable Diffusion
Stable Diffusion is a image generation model that can receive either text or image input and output network-generated images! 
We currently have Stable Diffusion v1.5 available, but are working on supporting other checkpoints:

- Stable Diffusion v1.5 Text2Image: `stable-diffusion-text`
- Stable Diffusion v1.5 Image2Image: `stable-diffusion-image`

You should supply this endpoint with the following data once deployed:

Once you've deployed a Stable Diffusion model, you can supply the enpoint with your input list of text/images and the standard Stable Diffusion model parameters. Here's an example of how to call the deployed endpoint:
```bash
curl -X POST 'https://inference.cerebrium.ai/runs/YOUR_ENDPOINT' \
-H 'Authorization: YOUR_API_KEY' \
-H 'Content-Type: application/json' \
-d '{
    [
        [
            {
                "text_in": "Mountain winds, and babbling springs, and moonlight seas"
            }
        ],
        {
            "num_samples": 1,
            "num_inference_steps": 50,
            "width": 512,
            "height": 512
        }
    ]
}'

```


### Language Models
#### Whisper
Whisper is a language generation model that receives audio data and performs transcription and or translation, then outputs a text response.
We currently have the following whisper models available:

- Whisper Tiny: `whisper-tiny`
- Whisper Base: `whisper-base`
- Whisper Medium: `whisper-medium`
- Whisper Large: `whisper-large`

Once you've deployed a Whisper model, you can supply the enpoint with a list of base-64 encoded audio files. Here's an example of how to call the deployed endpoint:
```bash
curl -X POST 'https://inference.cerebrium.ai/runs/YOUR_ENDPOINT' \
-H 'Authorization: YOUR_API_KEY' \
-H 'Content-Type: application/json' \
-d '[
        [
            {
                "audio_in": {
                    "b64_encoded": "'"$( base64 -i YOUR_AUDIO_PATH )"'",
                    "filetype": "mp3"
                }
            }
        ]
    ]'
```

