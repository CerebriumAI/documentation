---
title: "Prebuilt Models"
description: "Deploy prebuilt models to an API."
---

Cerebrium provides prebuilt models that you can deploy to an API. You can use these models to get started with Cerebrium easily.

## Deployment
Deploying a prebuilt model is largely similar to deploying a custom model. The only difference is that you do not need to upload a model file.
Instead, you specify which prebuilt model you want to deploy using the corresponding identifer.

```python
from cerebrium import deploy, model_type
# Deploy a prebuilt Whisper Model
endpoint = deploy((model_type.PREBUILT, "<MODEL_ENUM>"), 'my-flow', "<API_KEY>")
```
<Note>
    You can not use prebuilt models in ensembles or with post-processing functions. They should be contained within single model flows only.
</Note>

You can check out the available models below!

## Prebuilt Models
### Image Models
#### Stable Diffusion
Stable Diffusion is a image generation model that can receive either text or image input and output network-generated images! We currently have Stable Diffusion v2 available

- Stable Diffusion v2: `stable-diffusion-2`

Once you've deployed a Stable Diffusion model, you can supply the enpoint with string with what image you would like to generate.  Here's an example of how to call the deployed endpoint:

#### Request Parameters

<RequestExample>
```bash Request
  curl --location --request POST 'https://inference.cerebrium.ai/runs/<YOUR_ENDPOINT>' \
      --header 'Authorization: <API_KEY>' \
      --header 'Content-Type: application/json' \
      --data-raw '{
        "prompt": "a photo of an astronaut riding a horse on mars.",
        "webhook_endpoint": "https://your_url.com"
        }'
```
</RequestExample>

<ParamField header="Authorization" type="string" required>
  This is the Cerebrium API key used to authenticate your request. You can get it from your Cerebrium dashboard.
</ParamField>
<ParamField body="prompt" type="string" required>
   The prompt you would like Stable Diffusion to generate.
</ParamField>
<ParamField body="webhook_endpoint" type="string" optional>
   The url endpoint you would like us to send the image results once it has finished generating
</ParamField>

<ResponseExample>

```json Response
{
    "message": "Successfully generated image",
    "images": <BASE_64_STRING>
}
```
</ResponseExample>

#### Response Parameters

<ResponseField name="message" type="string" required>
  Whether of not the response was successful
</ResponseField>
<ResponseField name="images" type="string" required>
  A base64 encoded string of the image that you can convert into an image
</ResponseField>

### Language Models
#### Whisper
Whisper is a language generation model that receives audio data and performs transcription and or translation, then outputs a text response. It can process audio of any length and takes about 1 minute to process an hour of audio. We also return the timestamps of the transcription if you would like to create subtitles for the audio etc.
We currently have the following whisper models available below however if you would like any others contact support and we can quickly add it for you.

- Whisper Medium: `whisper-medium`

Once you've deployed a Whisper model, you can supply the enpoint with a base-64 encoded audio file.  Here's an example of how to call the deployed endpoint:

#### Request Parameters

<RequestExample>
```bash Request
  curl --location --request POST 'https://inference.cerebrium.ai/runs/<YOUR_ENDPOINT>' \
      --header 'Authorization: <API_KEY>' \
      --header 'Content-Type: application/json' \
      --data-raw '{
        "audio": "<BASE_64_STRING>"
        }'
```
</RequestExample>

<ParamField header="Authorization" type="string" required>
  This is the Cerebrium API key used to authenticate your request. You can get it from your Cerebrium dashboard.
</ParamField>
<ParamField body="audio" type="string" required>
   A base64 encoded string of the audio file you would like to transcribe/translate.
</ParamField>

<ResponseExample>

```json Response
{
    "text":" "<TEXT>",
    "segments": []
}
```
</ResponseExample>

#### Response Parameters

<ResponseField name="text" type="string" required>
  The text that has been transcribed or translated
</ResponseField>
<ResponseField name="segments" type="string" required>
  Detailed information about the transcription/translation.
</ResponseField>

#### MT0
MT0 is a model capable of following human instructions in dozens of languages. It is pretrained on a crosslingual task mixture (xP3) and the resulting model is capable of crosslingual generalization to unseen tasks & languages.You can read more [here](https://huggingface.co/bigscience/mt0-xl). We currently have the following MT0 models available below however if you would like any others contact support and we can quickly add it for you.

- mt0-xl: `mt0-xl`

Once you've deployed a MT0 model, you can supply the enpoint with a prompt.  Here's an example of how to call the deployed endpoint:

#### Request Parameters

<RequestExample>
```bash Request
  curl --location --request POST 'https://inference.cerebrium.ai/runs/<YOUR_ENDPOINT>' \
      --header 'Authorization: <API_KEY>' \
      --header 'Content-Type: application/json' \
      --data-raw '{
        "prompt": "Translate from french to English: Je t'aime."
    }'
```
</RequestExample>

<ParamField header="Authorization" type="string" required>
  This is the Cerebrium API key used to authenticate your request. You can get it from your Cerebrium dashboard.
</ParamField>
<ParamField body="prompt" type="string" required>
   The prompt you would like mt0 to process.
</ParamField>

<ResponseExample>

```json Response
{
    "result": "I love you"
}
```
</ResponseExample>

#### Response Parameters

<ResponseField name="result" type="string" required>
  The result generated from mt0
</ResponseField>


#### FLAN
FLAN, which stands for Fine-tuned LAnguage Net (FLAN), is a technique for instruction tuning to learn how to solve natural language processing tasks in general.
It can be used to answer questions or tasks across many languages - you can read more [here](https://ai.googleblog.com/2021/10/introducing-flan-more-generalizable.html). We currently have the following whisper models available below however if you would like any others contact support and we can quickly add it for you.

- Flan XL: `flan-xl`

Once you've deployed a FLAN model, you can supply the enpoint with a prompt.  Here's an example of how to call the deployed endpoint:

#### Request Parameters

<RequestExample>
```bash Request
  curl --location --request POST 'https://inference.cerebrium.ai/runs/<YOUR_ENDPOINT>' \
      --header 'Authorization: <API_KEY>' \
      --header 'Content-Type: application/json' \
      --data-raw '{
        "prompt": "translate English to German: How old are you?"
    }'
```
</RequestExample>

<ParamField header="Authorization" type="string" required>
  This is the Cerebrium API key used to authenticate your request. You can get it from your Cerebrium dashboard.
</ParamField>
<ParamField body="prompt" type="string" required>
   The prompt you would like FLAN to process.
</ParamField>

<ResponseExample>

```json Response
{
    "result": "Wie alt sind Sie?"
}
```
</ResponseExample>

#### Response Parameters

<ResponseField name="result" type="string" required>
  The result generated from FLAN
</ResponseField>


