---
title: Rime
description: Deploy Rime text-to-speech services on Cerebrium
---

<Note>
  Rime Partner Service is available from CLI version 1.39.0 and greater
</Note>

Cerebrium's partnership with [Rime](https://www.rime.ai/) allows you to easily deploy text-to-speech (TTS) services with simplified configuration and independent scaling. It
also allows you to run at much lower latencies and adhere to data privacy regulations by deploying in different regions.

## Configuration

Rime services use a simplified TOML configuration with the `[cerebrium.runtime.rime]` section. Create a cerebrium.toml file with the following:

```toml
[cerebrium.deployment]
name = "rime"

[cerebrium.runtime.rime]

[cerebrium.hardware]
cpu = 2
memory = 4
compute = "AMPERE_A10"
gpu_count = 1

[cerebrium.scaling]
min_replicas = 0
max_replicas = 2
cooldown = 120
replica_concurrency = 3
```

Run `cerebrium deploy` to deploy your Rime service. You should then see output like the following:

```
App Dashboard: https://dev-dashboard.cerebrium.ai/projects/p-xxxx/apps/p-xxxxx-rime
```

You can find the Deployment url in the output above. Then use the following curl request to make a request to your Rime service:

```
curl --location 'https://dev-api.cortex.cerebrium.ai/v4/p-xxxxx/rime/' \
--header 'Authorization: Bearer <RIME_API_KEY>' \
--header 'Content-Type: application/json' \
--header 'Accept: audio/pcm' \
--data '{
  "text": "I would love to have a conversation with you.",
  "speaker": "joy",
  "modelId": "mist"
}'
```

The RIME_API_KEY is the API key for your Rime service. You can find it in the Rime dashboard.

## Scaling and Concurrency

Rime services support independent scaling configurations:

- **min_replicas**: Minimum number of instances to maintain (0 for scale-to-zero). Recommended to set to 1.
- **max_replicas**: Maximum number of instances that can be created during high load.
- **replica_concurrency**: Number of concurrent requests each instance can handle. Recommended to set to 3.
- **cooldown**: Time in seconds that an instance remains active after processing its last request. Recommended to set to 120.
- **compute**: The instance type to use for the service. Recommended to set to `AMPERE_A10`.

Adjust these parameters based on your expected traffic patterns and latency requirements.

For further documentation on Rime, see the [Rime documentation](https://docs.rime.ai/).
