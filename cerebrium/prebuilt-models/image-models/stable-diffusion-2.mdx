---
title: "Stable Diffusion"
description: "Stable Diffusion is an image generation model that can receive either text or image input and output network-generated images"
api: "POST https://run.cerebrium.ai/dreambooth-webhook/predict"
---

To deploy the model, you can use the identifier below:

- Stable Diffusion v2: `stable-diffusion`

We are currently using the "stabilityai/stable-diffusion-2-1" model. Once you've deployed a Stable Diffusion model, you can supply the endpoint with string with what image you would like to generate. Here's an example of how to call the deployed endpoint:

#### Request Parameters

<RequestExample>
```bash Request
  curl --location --request POST 'https://run.cerebrium.ai/dreambooth-webhook/predict' \
      --header 'Authorization: <API_KEY>' \
      --header 'Content-Type: application/json' \
      --data-raw '{
        "prompt": "a photo of an astronaut riding a horse on mars.",
        "height": 768,
        "width": 512,
        "num_inference_steps": 60,
        "guidance_scale": 8,
        "num_images_per_prompt": 2,
        "negative_prompt": "no sky",
        "webhook_endpoint": "https://your_url.com"
        }'
```
</RequestExample>

<ParamField header="Authorization" type="string" required>
  This is the Cerebrium API key used to authenticate your request. You can get
  it from your Cerebrium dashboard.
</ParamField>
<ParamField body="prompt" type="string" required>
  The prompt you would like Stable Diffusion to generate.
</ParamField>
<ParamField body="height" type="integer" optional>
  The height of the generated image which defaults to 512px. This is an optional
  parameter
</ParamField>
<ParamField body="width" type="integer" optional>
  The width of the generated image which defaults to 512px. This is an optional
  parameter
</ParamField>
<ParamField body="num_inference_steps" type="integer" optional>
  The number of steps you would like Dreambooth to take to generate the image.
  In general, the results are better the more steps you use, however the more
  steps, the longer the generation takes. It defaults to 50 steps and is an
  optional parameter.
</ParamField>
<ParamField body="guidance_scale" type="float" optional>
  A way to increase the adherence to the conditional signal that guides the
  generation (text, in this case) as well as overall sample quality. In simple
  terms it forces the generation to better match the prompt potentially at the
  cost of image quality or diversity. This defaults to 7.5 and is an optional
  parameter.
</ParamField>
<ParamField body="num_images_per_prompt" type="integer" optional>
  The number of image variations you would like the model to generate. This is
  an optional parameter which defaults to 1.
</ParamField>
<ParamField body="negative_prompt" type="string" optional>
  The negative prompt is a parameter that tells Stable Diffusion what you donâ€™t
  want to see in the generated images. This is an optional parameter that has an
  empty default value.
</ParamField>
<ParamField body="webhook_endpoint" type="string" optional>
  The url endpoint you would like us to send the image results to once it has
  finished generating. We recommend this for long running tasks if you are
  generating multiple images with many steps.
</ParamField>

<ResponseExample>

```json Response
{
    "run_id": "<UUID_STRING>",
    "run_time_ms": <NUMBER>,
    "message": "Successfully generated images",
    "result": [<BASE_64_STRING>]
}
```

</ResponseExample>

#### Response Parameters

<ResponseField name="run_id" type="string" required>
  A unique identifier for the run that you can use to associate prompts with
  webhook endpoints.
</ResponseField>
<ResponseField name="message" type="string" required>
  Whether of not the response was successful
</ResponseField>
<ResponseField name="result" type="string" required>
  An array of base64 encoded strings of the image that you can convert into an
  image
</ResponseField>
