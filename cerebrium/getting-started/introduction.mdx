---
title: Introduction
description: Getting started on the Cerebrium platform
---

Cerebrium is a cloud GPU infrastructure platform that transforms how teams deploy and scale machine learning apps. By handling the complex infrastructure – GPUs, Kubernetes, queues, monitoring, and scaling – Cerebrium lets teams focus on building apps that deliver value.

The platform achieves this through rapid cold starts (Less than 5 seconds), flexible GPU options, automated scaling (1 to 10,000+ requests), and simple deployment processes. With 99.9% uptime and continuous weekly improvements based on user feedback, Cerebrium provides the reliability needed for production ML apps.

## Getting Started

Setting up and deploying an app on Cerebrium takes just a few steps:

### 1. Install the CLI

```bash
pip install cerebrium
cerebrium login  # Redirects to your browser for authentication
```

### 2. Initialize a Project

```bash
cerebrium init my-first-app
cd my-first-app
```

This creates a basic project with `main.py` for app code and `cerebrium.toml` for configuration. This is was the main.py file contains:

```python
def run(param_1: str, param_2: str, run_id):  # run_id is optional, injected by Cerebrium at runtime
    my_results = {"1": param_1, "2": param_2}
    my_status_code = 200

    return {"my_result": my_results, "status_code": my_status_code}
```

This will turn the function into a callable endpoint that accepts json parameters (param_1 and param_2) and can scale to 1000s of requests.

### 3. Deploy an App

```bash
cerebrium deploy
```

The app now builds and deploys, typically within a few seconds. Check out a detailed description of the deployment process for more information. Once deployed, an app becomes callable through an endpoint `https://api.cortex.cerebrium.ai/v4/{project-id}/{app-name}/{function-name}`.

You can also call it using:

```bash
cerebrium run my-first-app:run -d '{"param_1": "Hello", "param_2": "World"}'
```

For complete CLI documentation, see the [CLI Reference](/cli-reference/cli-reference).

## How It Works

Cerebrium uses containerization to ensure consistent environments and reliable scaling for apps. When code is deployed, Cerebrium packages it with all necessary dependencies into a container image. This image serves as a blueprint for creating instances that handle incoming requests. The system automatically manages scaling, creating new instances when traffic increases and removing them during quiet periods.

For a detailed explanation of how Cerebrium builds and manages container images, see our [Defining Container Images Guide](/cerebrium/container-images/defining-container-images).

<Info>
  Content-Aware Storage forms the foundation of Cerebrium's speed. This system
  intelligently manages container images by understanding their content
  structure. When launching new instances, it pulls only the specific files.
  This targeted approach significantly reduces cold start times and optimizes
  resource usage.
</Info>

Join our [Discord](https://discord.gg/ATj6USmeE2) community for support and updates, or reach out to [support@cerebrium.ai](mailto:support@cerebrium.ai) with any questions.
